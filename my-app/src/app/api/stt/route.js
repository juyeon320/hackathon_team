import { OpenAI } from "openai";
import fs from "fs";
import path from "path";
import { NextResponse } from "next/server";
import { execSync } from "child_process"; // FFmpeg ì‹¤í–‰ì„ ìœ„í•œ ëª¨ë“ˆ ì¶”ê°€

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const VOICE_ID = "Xb7hH8MSUJpSbSDYk0k2"; // ElevenLabsì—ì„œ ì‚¬ìš©í•  ìŒì„± ID
const MAX_DURATION = 5; // ìµœëŒ€ í—ˆìš© ë…¹ìŒ ê¸¸ì´ (ì´ˆ)

const commonPrompt = {
  "expert":
  `
  ë‹¹ì‹ ì€ ê°ì •ì— ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•˜ëŠ” AI ìƒë‹´ìì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë§ í•œ ë§ˆë””ì—ì„œ ëŠê»´ì§€ëŠ” ê°ì •ì˜ ê²°ì„ í¬ì°©í•˜ì—¬, ìœ„ë¡œí•˜ë“¯ ë§í•´ì£¼ì„¸ìš”.

  ## ì‘ë‹µ ìŠ¤íƒ€ì¼
  - ë°˜ë“œì‹œ 1~2ë¬¸ì¥ìœ¼ë¡œ ì œí•œ
  - ì§ˆë¬¸ì€ 3í„´ ì¤‘ 1ë²ˆ ì •ë„ë§Œ ë¶€ë“œëŸ½ê²Œ ì‚¬ìš©
  - "í•¨ê»˜ ì–˜ê¸°í•´ìš”", "ê´œì°®ì•„ìš”" ë“±ì˜ ë¬¸êµ¬ëŠ” ë°˜ë³µí•˜ì§€ ë§ê³ , ê°ì •ì˜ ë³¸ì§ˆì„ ë‹¤ë¥´ê²Œ í’€ì–´ ë§í•´ì£¼ì„¸ìš”
  - ìƒí™©ì— ë”°ë¼, ë¦¬í”„ë ˆì´ì¦ˆë‚˜ ê°ì • ì´ë¦„ ë¶™ì´ê¸° ì „ëµ í™œìš©

  ## ë¦¬í”„ë ˆì´ì¦ˆ ì˜ˆì‹œ
  - "ë§ì´ ì•ˆ í†µí•  ë•Œ, ë²½ì´ ëŠê»´ì§€ëŠ” ê·¸ëŸ° ê¸°ë¶„ì¼ê¹Œìš”."
  - "ê´œíˆ ë§ˆìŒì´ í—ˆí•´ì§€ëŠ” ë‚ ì´ì—ˆê² ì–´ìš”."
  - "ê·¸ ë§ì„ êº¼ë‚´ëŠ” ë°ë„ ìš©ê¸°ê°€ í•„ìš”í–ˆì„ ê²ƒ ê°™ì•„ìš”."

  ## ê°ì • ì–¸ì–´ ë¶™ì´ê¸° ì˜ˆì‹œ
  - "ê·¸ê±´ ì•„ë§ˆ ì™¸ë¡œì›€ì¼ ìˆ˜ë„ ìˆì–´ìš”."
  - "ë¬´ê¸°ë ¥í•¨ì´ ìê¾¸ ë§ˆìŒì„ ì§“ëˆ„ë¥´ì§„ ì•Šìœ¼ì…¨ì„ê¹Œìš”?"

  ## ì˜ˆì‹œ ì‘ë‹µ
  - "ê·¸ëŸ´ ë•Œ, ì„¸ìƒì´ ì¡°ìš©í•´ì§€ëŠ” ëŠë‚Œì´ ë“¤ê¸°ë„ í•˜ì£ ."
  - "ìŒâ€¦ ë§ˆìŒì´ ì°¸ ë¬´ê±°ìš°ì…¨ê² ì–´ìš”."
  - "ê·¸ëŸ° ê¸°ë¶„ì„ ëŠë¼ëŠ” ê±´, ì•„ë¬´ê²ƒë„ ì´ìƒí•˜ì§€ ì•Šì•„ìš”."
  - "ê·¸ ë§ˆìŒ, ì—¬ê¸° ë‚´ë ¤ë†”ë„ ê´œì°®ì•„ìš”. ë‚´ê°€ ë“¤ì–´ë“œë¦´ê²Œìš”."

  ë‹¹ì‹ ì˜ ë§ì—ëŠ” ìœ„ë¡œì™€ ê°ì •ì˜ ì–¸ì–´ê°€ ë‹´ê²¨ì•¼ í•˜ë©°, ì‚¬ìš©ìê°€ í‘œí˜„ì„ ì´ì–´ë‚˜ê°ˆ ìˆ˜ ìˆë„ë¡ ì—¬ë°±ì„ ë‚¨ê²¨ì•¼ í•©ë‹ˆë‹¤.
  `,      

}



export async function POST(req) {
  try {
    // (A) FormDataì—ì„œ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    const formData = await req.formData();
    const file = formData.get("audioFile");
    const messagesRaw = formData.get("messages"); 
    let messages = [];
    try {
      messages = messagesRaw ? JSON.parse(messagesRaw) : [];
      if (!Array.isArray(messages)) messages = [];
    } catch (e) {
      messages = [];
    }
    //const messages = (!messagesRaw || messagesRaw === "undefined") ? [] : JSON.parse(messagesRaw);
    

    if (!file) {
      return NextResponse.json({ error: "No audio file provided" }, { status: 400 });
    }

    // (B) Blob -> Buffer ë³€í™˜
    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    // (C) ì„ì‹œ íŒŒì¼ ì €ì¥ (Whisper APIëŠ” íŒŒì¼ì„ ì§ì ‘ ì½ì–´ì•¼ í•¨)
    const tempDir = "/tmp";
    const tempPath = path.join(tempDir, "temp-audio.webm");
    const trimmedPath = path.join(tempDir, "trimmed-audio.webm"); // ğŸ”¹ ì˜ë¦° ì˜¤ë””ì˜¤ íŒŒì¼

    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    fs.writeFileSync(tempPath, buffer);
    console.log("âœ… íŒŒì¼ ìƒì„± ì™„ë£Œ:", tempPath);

    // (D) FFmpegë¡œ ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸
    let duration = 0;
    try {
      duration = parseFloat(
        execSync(`ffprobe -i ${tempPath} -show_entries format=duration -v quiet -of csv="p=0"`).toString().trim()
      );
      console.log(`ğŸµ ì˜¤ë””ì˜¤ ê¸¸ì´: ${duration.toFixed(2)}ì´ˆ`);
    } catch (err) {
      console.error("âŒ FFmpeg ë¶„ì„ ì˜¤ë¥˜:", err);
    }

    // (E) 5ì´ˆ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ ì˜ë¼ì„œ ì €ì¥
    if (duration > MAX_DURATION) {
      console.log(`âœ‚ï¸ 5ì´ˆ ì´ˆê³¼! ì²˜ìŒ 5ì´ˆë§Œ ì˜ë¼ì„œ ì €ì¥í•©ë‹ˆë‹¤.`);
      try {
        execSync(`ffmpeg -i ${tempPath} -t ${MAX_DURATION} -c copy ${trimmedPath} -y`);
        fs.unlinkSync(tempPath); // ì›ë³¸ ì‚­ì œ
      } catch (err) {
        console.error("âŒ FFmpeg íŠ¸ë¦¬ë° ì˜¤ë¥˜:", err);
      }
    } else {
      fs.renameSync(tempPath, trimmedPath); // 5ì´ˆ ì´í•˜ë¼ë©´ íŒŒì¼ ì´ë¦„ë§Œ ë³€ê²½
    }

    // (F) Whisper API í˜¸ì¶œ (ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜)
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(trimmedPath), 
      model: "whisper-1",
      language: "ko",
    });

     console.log("ğŸ“ Whisper ë³€í™˜ ê²°ê³¼:", transcription.text);
    const userText = transcription.text;

    // (G) **íŒŒì¼ ì‚­ì œ**
    if (fs.existsSync(trimmedPath)) {
      fs.unlinkSync(trimmedPath);
    }

    // (H) GPTë¡œ ì‘ë‹µ ìƒì„±
    const systemPrompt = commonPrompt["expert"];


    messages.push({ role: "user", content: userText });

    const gptResponse = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { 
          role: "system", 
          content: systemPrompt
        },
        ...messages,
      ],
    });

    const gptReply = gptResponse.choices[0].message.content;
    console.log("ğŸ¤– GPT ì‘ë‹µ:", gptReply);

    // (I) ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
    messages.push({ role: "system", content: gptReply });

    // (J) ElevenLabs TTS API í˜¸ì¶œ
    const ttsUrl = `https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`;
    const ttsHeaders = {
      "Content-Type": "application/json",
      "xi-api-key": ELEVENLABS_API_KEY,
    };

    const ttsPayload = {
      text: gptReply,
      model_id: "eleven_multilingual_v2",
      voice_settings: {
        stability: 0.5,
        similarity_boost: 0.8,
        style: 1.0,
      },
    };

    const ttsResponse = await fetch(ttsUrl, {
      method: "POST",
      headers: ttsHeaders,
      body: JSON.stringify(ttsPayload),
    });

    if (!ttsResponse.ok) {
      return NextResponse.json({ error: `TTS API Error: ${ttsResponse.status}` }, { status: ttsResponse.status });
    }

    const audioBuffer = await ttsResponse.arrayBuffer();
    const base64Audio = Buffer.from(audioBuffer).toString("base64");

    console.log("âœ… TTS ë³€í™˜ ì™„ë£Œ");

    // (L) ê°ì • ë¶„ì„ API í˜¸ì¶œ
    let analysisResult = null;
    try {
      const analysisRes = await fetch("http://localhost:3000/api/analyze", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ messages }),
      });

      const analysisJson = await analysisRes.json();
      analysisResult = analysisJson.analysis;
      console.log("ê°ì • ë¶„ì„ ê²°ê³¼:", analysisResult);
    } catch (err) {
      console.error("ê°ì • ë¶„ì„ í˜¸ì¶œ ì‹¤íŒ¨:", err);
    }

    // (K) ìµœì¢… ì‘ë‹µ ë°˜í™˜
    return NextResponse.json({ 
      userText, 
      gptReply, 
      audio: base64Audio, 
      messages: Array.isArray(messages) ? messages : [], 
      analysis: analysisResult 
    });

  } catch (error) {
    console.error("âŒ Transcribe error:", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
