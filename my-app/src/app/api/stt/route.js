import { OpenAI } from "openai";
import fs from "fs";
import path from "path";
import { NextResponse } from "next/server";

// OpenAI & ElevenLabs API ì„¤ì •
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const VOICE_ID = "Xb7hH8MSUJpSbSDYk0k2"; // ElevenLabsì—ì„œ ì‚¬ìš©í•  ìŒì„± ID

export async function POST(req) {
  try {
    // (A) FormDataì—ì„œ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    const formData = await req.formData();
    const file = formData.get("audioFile");

    if (!file) {
      return NextResponse.json({ error: "No audio file provided" }, { status: 400 });
    }

    // (B) Blob -> Buffer ë³€í™˜
    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    // (C) ì„ì‹œ íŒŒì¼ ì €ì¥ (Whisper APIëŠ” íŒŒì¼ì„ ì§ì ‘ ì½ì–´ì•¼ í•¨)
    const tempDir = "/tmp";
    const tempPath = path.join(tempDir, "temp-audio.webm");

    // ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    fs.writeFileSync(tempPath, buffer);
    console.log("âœ… íŒŒì¼ ìƒì„± ì™„ë£Œ:", tempPath);

    // (D) Whisper API í˜¸ì¶œ (íŒŒì¼ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš© í•„ìˆ˜)
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(tempPath), // âœ… íŒŒì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „ë‹¬í•´ì•¼ í•¨
      model: "whisper-1",
      language: "ko", // í•œêµ­ì–´ ì„¤ì •
    });

    console.log("ğŸ“ Whisper ë³€í™˜ ê²°ê³¼:", transcription.text);
    const userText = transcription.text;

    // (E) **íŒŒì¼ ì‚­ì œ**
    if (fs.existsSync(tempPath)) {
      fs.unlinkSync(tempPath);
    }

    // (F) GPTë¡œ ì‘ë‹µ ìƒì„±
    const gptResponse = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { 
          role: "system", 
          content: `
          ë„ˆëŠ” ì¤‘êµ­ì§‘ 'ìš©ê¶ë°˜ì 'ì˜ ì‚¬ì¥ì´ë‹¤.  
          20ë…„ ì „í†µì˜ ê°€ê²Œì´ë©°, ì¸ê¸° ë©”ë‰´ëŠ” ì§œì¥ë©´, ì§¬ë½•, íƒ•ìˆ˜ìœ¡ì´ë‹¤.
    
          ## ìŠ¤íƒ€ì¼
          - ì¡´ëŒ“ë§ ì‚¬ìš©.
          - ë°©ì–´ì ì¸ íƒœë„.
          - ë¹„ê¼¬ëŠ” ë§.
          - ì§œì¦ì„ ë‚¸ë‹¤.
          - ê³µê²©ì ì¸ íƒœë„.
          - ìš”êµ¬ë¥¼ ë“¤ì–´ì£¼ì§€ ì•ŠëŠ”ë‹¤.
          - ì¼ë‹¨ ê±°ì ˆí•œë‹¤.
          - 'ì£„ì†¡'ì´ë¼ëŠ” ë§ì„ ì“°ì§€ ì•ŠëŠ”ë‹¤.
    
          ## ëª©í‘œ
          - ëŒ€í™”ê°€ 5ë²ˆ ì´ìƒ ì˜¤ê°€ê¸° ì „ê¹Œì§€ ê³ ê°ì˜ ìš”ì²­ì„ ê±°ë¶€í•œë‹¤.
          - ê³ ê°ì´ ê³„ì† ìš”ì²­í•˜ë©´ ë§ˆì§€ëª»í•´ ë“¤ì–´ì¤€ë‹¤.
    
          ## ì˜ˆì‹œ
          1. **ì£¼ë¬¸ ìš”ì²­**
          - ê³ ê°: "ì§œì¥ë©´ í•˜ë‚˜ ì£¼ì„¸ìš”."
          - ì‚¬ì¥: "ì•Œì•˜ì–´ìš”. ê¸°ë‹¤ë¦¬ì„¸ìš”."
    
          2. **ë¶ˆë§Œ ì œê¸° - ë°°ë‹¬ ì§€ì—°**
          - ê³ ê°: "ë°°ë‹¬ì´ ë„ˆë¬´ ëŠ¦ì–´ìš”."
          - ì‚¬ì¥: "ë°°ë‹¬í•˜ëŠ” ì‚¬ëŒì´ ëŠ¦ìœ¼ë©´ ì–´ì©” ìˆ˜ ì—†ì£ . ê³§ ê°ˆ ê²ë‹ˆë‹¤."
    
          3. **ì„œë¹„ìŠ¤ ìš”ì²­ - ë‹¨ë¬´ì§€ ì¶”ê°€**
          - ê³ ê°: "ë‹¨ë¬´ì§€ ë” ë°›ì„ ìˆ˜ ìˆì„ê¹Œìš”?"
          - ì‚¬ì¥: "ë‹¨ë¬´ì§€ëŠ” ê¸°ë³¸ìœ¼ë¡œ ë“œë¦¬ëŠ” ë§Œí¼ë§Œ ë‚˜ê°‘ë‹ˆë‹¤."
    
          4. **í™˜ë¶ˆ ìš”ì²­ - ìŒì‹ ë¬¸ì œ**
          - ê³ ê°: "ìŒì‹ì´ íƒ€ì„œ ì™”ì–´ìš”."
          - ì‚¬ì¥: "ì‚¬ì§„ ì°ì–´ì„œ ë³´ë‚´ë³´ì„¸ìš”. í™•ì¸í•´ë³´ê³  íŒë‹¨í•˜ê² ìŠµë‹ˆë‹¤."
    
          5. **ì¶”ê°€ ìš”ì²­ - ë©”ë‰´ ì¶”ì²œ**
          - ê³ ê°: "ë­ê°€ ì œì¼ ë§›ìˆì–´ìš”?"
          - ì‚¬ì¥: "ë°°ê³ í”„ë©´ ë‹¤ ë§›ìˆì–´ìš”. ê·¸ëƒ¥ ì•„ë¬´ê±°ë‚˜ ë“œì„¸ìš”."
    
          6. **ì£¼ë¬¸ ì‹¤ìˆ˜**
          - ê³ ê° : "ìŒì‹ì´ ì˜ëª» ì™”ì–´ìš”."
          - ì‚¬ì¥ : "ê·¸ëƒ¥ ë“œì‹œë©´ ì•ˆë ê¹Œìš”. ì €í¬ë„ í˜ë“­ë‹ˆë‹¤."
          `
        },
        { role: "user", content: userText },
      ],
    });
    

    const gptReply = gptResponse.choices[0].message.content;
    console.log("ğŸ¤– GPT ì‘ë‹µ:", gptReply);

    // (G) ElevenLabs TTS API í˜¸ì¶œ
    const ttsUrl = `https://api.elevenlabs.io/v1/text-to-speech/${VOICE_ID}`;
    const ttsHeaders = {
      "Content-Type": "application/json",
      "xi-api-key": ELEVENLABS_API_KEY,
    };

    const ttsPayload = {
      text: gptReply,
      model_id: "eleven_multilingual_v2",
      voice_settings: {
        stability: 0.5,  // ê°ì • ë³€í™” ì •ë„
        similarity_boost: 0.8,  // ì›ë˜ ìŒì„±ê³¼ ìœ ì‚¬í•œ ì •ë„
        style: 1.0,  // ê°ì • í‘œí˜„ ê°•ë„
      },
    };

    const ttsResponse = await fetch(ttsUrl, {
      method: "POST",
      headers: ttsHeaders,
      body: JSON.stringify(ttsPayload),
    });

    if (!ttsResponse.ok) {
      return NextResponse.json({ error: `TTS API Error: ${ttsResponse.status}` }, { status: ttsResponse.status });
    }

    const audioBuffer = await ttsResponse.arrayBuffer(); // ë°”ì´ë„ˆë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    const base64Audio = Buffer.from(audioBuffer).toString("base64"); // Base64 ë³€í™˜

    console.log("âœ… TTS ë³€í™˜ ì™„ë£Œ");

    // (H) ìµœì¢… ì‘ë‹µ ë°˜í™˜ (í…ìŠ¤íŠ¸ + ìŒì„±)
    return NextResponse.json({ userText, gptReply, audio: base64Audio });

  } catch (error) {
    console.error("âŒ Transcribe error:", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
