import { OpenAI } from "openai";
import fs from "fs";
import path from "path";
import { NextResponse } from "next/server";

// OpenAI API ì„¤ì •
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export async function POST(req) {
  try {
    // (A) FormDataì—ì„œ íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    const formData = await req.formData();
    const file = formData.get("audioFile");

    if (!file) {
      return NextResponse.json({ error: "No audio file provided" }, { status: 400 });
    }

    // (B) Blob -> Buffer ë³€í™˜
    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    // (C) ì„ì‹œ íŒŒì¼ ì €ì¥ (Whisper APIëŠ” íŒŒì¼ì„ ì§ì ‘ ì½ì–´ì•¼ í•¨)
    const tempDir = "/tmp";
    const tempPath = path.join(tempDir, "temp-audio.webm");

    // ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }

    fs.writeFileSync(tempPath, buffer);
    console.log("âœ… íŒŒì¼ ìƒì„± ì™„ë£Œ:", tempPath);

    // (D) Whisper API í˜¸ì¶œ (íŒŒì¼ ìŠ¤íŠ¸ë¦¼ ì‚¬ìš© í•„ìˆ˜)
    const transcription = await openai.audio.transcriptions.create({
      file: fs.createReadStream(tempPath), // âœ… íŒŒì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „ë‹¬í•´ì•¼ í•¨
      model: "whisper-1",
      language: "ko", // í•œêµ­ì–´ ì„¤ì •
    });

    console.log("ğŸ“ Whisper ë³€í™˜ ê²°ê³¼:", transcription.text);

    // (E) **íŒŒì¼ ì‚­ì œ**
    if (fs.existsSync(tempPath)) {
      fs.unlinkSync(tempPath);
    }

    // (F) ë³€í™˜ëœ í…ìŠ¤íŠ¸ ë°˜í™˜
    return NextResponse.json({ text: transcription.text });
  } catch (error) {
    console.error("âŒ Transcribe error:", error);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}
