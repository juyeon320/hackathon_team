"use client";

import { useState, useRef, useEffect } from "react";
import { useSearchParams, useRouter } from "next/navigation";
import "../styles/globals.css"; 
import Footer from "@/component/footer";
import Title from "@/component/Title"; 

export default function ChatPage() {
  const searchParams = useSearchParams();
  const router = useRouter();
  const category = searchParams.get("category");
  const difficulty = searchParams.get("difficulty");

  const MAX_RECORDS = 3; // ğŸ”¹ ìµœëŒ€ ë…¹ìŒ íšŸìˆ˜ ì„¤ì •
  const [messages, setMessages] = useState([
    { role: "system", content: `ì•ˆë…•í•˜ì„¸ìš”! "${category}" ì¹´í…Œê³ ë¦¬ì˜ "${difficulty}" ë‚œì´ë„ë¡œ ëŒ€í™”í•´ìš”.` },
  ]);
  const [recordCount, setRecordCount] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [audioSrc, setAudioSrc] = useState(null);
  const [isConversationEnded, setIsConversationEnded] = useState(false); // ğŸ”¹ ì¢…ë£Œ ìƒíƒœ ì¶”ê°€
  const mediaRecorderRef = useRef(null);
  const audioChunksRef = useRef([]);
  const audioRef = useRef(null);
  const [isPlaying, setIsPlaying] = useState(false); // ğŸ”¹ AI ìŒì„±ì´ ì¬ìƒ ì¤‘ì¸ì§€ ì—¬ë¶€

  useEffect(() => {
    console.log("ğŸ” í˜„ì¬ messages ìƒíƒœ:", messages);
  }, [messages]);
  
  // ğŸ™ï¸ ë…¹ìŒ ì‹œì‘ (5ì´ˆ í›„ ìë™ ì¤‘ì§€)
  const startRecording = async () => {
    if (isRecording || isPlaying || recordCount >= MAX_RECORDS) return; // ğŸ”¹ ìµœëŒ€ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ì‹¤í–‰ ì•ˆ í•¨

    console.log(`ğŸ¤ ë…¹ìŒ ì‹œì‘! í˜„ì¬ ë…¹ìŒ íšŸìˆ˜: ${recordCount}/${MAX_RECORDS}`);
    audioChunksRef.current = [];
    setAudioSrc(null);

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        console.log("â¹ï¸ ìë™ ë…¹ìŒ ì¤‘ì§€ë¨! ë°ì´í„° í¬ê¸°:", audioChunksRef.current.length);
        setRecordCount(prev => prev + 1);
        await handleTranscribeAndAskGPT(audioChunksRef.current);
      };

      mediaRecorder.start();
      setIsRecording(true);

      // 5ì´ˆ í›„ ìë™ìœ¼ë¡œ ì¤‘ì§€
      setTimeout(() => {
        stopRecording();
      }, 5000);
      
    } catch (error) {
      alert("ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.");
    }
  };

  // â¹ï¸ ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (!mediaRecorderRef.current) return;
    console.log("â¹ï¸ ë…¹ìŒ ì¤‘ì§€ ìš”ì²­ë¨");
    mediaRecorderRef.current.stop();
    setIsRecording(false);
  };

  // ğŸ¤ STT + GPT + TTS API í˜¸ì¶œ
  const handleTranscribeAndAskGPT = async (chunks) => {
    if (chunks.length === 0) return;

    const blob = new Blob(chunks, { type: "audio/webm" });
    const formData = new FormData();
    formData.append("audioFile", blob, "recording.webm");
    formData.append("messages", JSON.stringify(messages));
    formData.append("category", category); 
    formData.append("difficulty", difficulty); 

    try {
      const res = await fetch("/api/stt", {
        method: "POST",
        body: formData,
      });

      const data = await res.json();
      const { userText, gptReply, audio, messages: updatedMessages } = data;
      console.log("ğŸ¤ ìœ ì € ì…ë ¥:", userText);
    console.log("ğŸ¤– GPT ì‘ë‹µ:", gptReply);
    console.log("ğŸ”„ ì—…ë°ì´íŠ¸ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸:", updatedMessages);
      setMessages(updatedMessages);

      if (audio) {
        const audioData = `data:audio/mp3;base64,${audio}`;
        setAudioSrc(audioData);

        // ğŸ”¹ AI ìŒì„± ì¬ìƒ ì‹œì‘
        setIsPlaying(true);

        setTimeout(() => {
          if (audioRef.current) {
            audioRef.current.play();
            console.log("ğŸ”Š AI ìŒì„± ì¬ìƒ ì‹œì‘");
          }
        }, 500);
      }

      // ğŸ”¹ íšŸìˆ˜ ì´ˆê³¼ í›„ ì¢…ë£Œ ë²„íŠ¼ í‘œì‹œ
      if (recordCount + 1 >= MAX_RECORDS) {
        setIsConversationEnded(true);
      }
      
    } catch (err) {
      alert("ì˜¤ë¥˜ ë°œìƒ: " + err.message);
    }
  };

  // ğŸ” **AI ìŒì„±ì´ ëë‚œ í›„, 1ì´ˆ í›„ ë‹¤ì‹œ ë…¹ìŒ ì‹œì‘ (ë‹¨, ìµœëŒ€ íšŸìˆ˜ ì´ˆê³¼ ì‹œ ì¢…ë£Œ ë²„íŠ¼ í‘œì‹œ)**
  useEffect(() => {
    if (!isPlaying && audioSrc) {
      if (recordCount < MAX_RECORDS) {
        console.log("ğŸ” AI ìŒì„±ì´ ëë‚¬ìœ¼ë¯€ë¡œ 1ì´ˆ í›„ ë‹¤ì‹œ ë…¹ìŒ ì‹œì‘!");
        setTimeout(() => {
          startRecording();
        }, 1000); // ğŸ”¹ 1ì´ˆ ë”œë ˆì´ í›„ ë…¹ìŒ ì‹œì‘
      }
    }
  }, [isPlaying]);

  // ğŸ“Œ **"ì¢…ë£Œ" ë²„íŠ¼ í´ë¦­ ì‹œ ê²½í—˜ì¹˜ í˜ì´ì§€ë¡œ ì´ë™**
  const handleEndConversation = () => {
    router.push(`/experience?difficulty=${difficulty}`);
  };

  return (
    <div className="min-h-screen flex flex-col items-center justify-start bg-cover bg-center pt-16"
      style={{ backgroundImage: "url('/images/background2.jpg')" }}>
      
      <Title>í¬ë¹„ì•¼</Title>

{/* ì±„íŒ… ë©”ì‹œì§€ ë°•ìŠ¤ */}
<div className="w-full max-w-md h-64 overflow-y-auto border border-gray-300 mb-4 p-4 bg-white rounded-lg shadow-lg flex flex-col gap-2">
  {Array.isArray(messages) ? (
    messages.map((msg, index) => {
      console.log(`ğŸ” ë©”ì‹œì§€ ${index}:`, msg); // ë””ë²„ê¹…ìš©

      // ì—­í•  ë¶„ë¥˜
      const isSystemMessage = msg.role === "system" && index === 0; // ì²« ì‹œìŠ¤í…œ ë©”ì‹œì§€
      const isGPTResponse = msg.role === "system" && index !== 0; // ì´í›„ GPT ì‘ë‹µ
      const isUserMessage = msg.role === "user";

      console.log("u",isUserMessage);
      return (
        <div key={index} className={`flex ${isUserMessage ? "justify-start" : "justify-end"}`}>
          <div
            className={`p-3 max-w-[75%] rounded-lg text-sm ${
              isSystemMessage
                ? "bg-yellow-400 text-black text-center w-full" // ì´ˆê¸° ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ë…¸ë€ìƒ‰ ì¤‘ì•™ ì •ë ¬
                : isUserMessage
                ? "bg-blue-500 text-black self-start" // ìœ ì € ë©”ì‹œì§€ëŠ” ì™¼ìª½ (íŒŒë€ìƒ‰)
                : "bg-gray-600 text-blue self-end" // GPT ì‘ë‹µì€ ì˜¤ë¥¸ìª½ (íšŒìƒ‰)
            }`}
          >
            {msg.content}
          </div>
        </div>
      );
    })
  ) : (
    <p className="text-center text-red-500">
      âš ï¸ ì˜¤ë¥˜: messagesê°€ ë°°ì—´ì´ ì•„ë‹™ë‹ˆë‹¤. í˜„ì¬ ê°’: {JSON.stringify(messages)}
    </p>
  )}
</div>


      {/* ğŸ”¹ ë…¹ìŒ ë²„íŠ¼ ë˜ëŠ” ì¢…ë£Œ ë²„íŠ¼ (ëŒ€í™” íšŸìˆ˜ ì´ˆê³¼ ì‹œ "ì¢…ë£Œ" ë²„íŠ¼ í‘œì‹œ) */}
      <div className="flex flex-col items-center justify-center mt-12">
        <div className="w-[400px] h-[400px] bg-gray-300 rounded-full flex items-center justify-center shadow-lg">
          {!isConversationEnded ? (
            <button 
              onClick={startRecording} 
              className={`px-6 py-3 text-lg font-bold rounded-lg transition-all duration-300
                ${isRecording ? "bg-red-600 animate-pulse" : "bg-gray-400 text-gray-800 hover:bg-gray-500"}`}
              disabled={isRecording || isPlaying} // ë…¹ìŒ ì¤‘ì´ê±°ë‚˜ ìŒì„±ì´ ì¬ìƒ ì¤‘ì´ë©´ ë¹„í™œì„±í™”
            >
              {isRecording ? "â¹ï¸ ë…¹ìŒ ì¤‘ (5ì´ˆ)" : isPlaying ? "ğŸ”Š AI ì‘ë‹µ ì¤‘" : "ğŸ™ï¸ ì‹œì‘"}
            </button>
          ) : (
            <button 
              onClick={handleEndConversation} 
              className="px-6 py-3 text-lg font-bold bg-blue-600 text-white rounded-lg shadow-md hover:bg-blue-700 transition duration-200"
            >
              ì¢…ë£Œ
            </button>
          )}
        </div>
      </div>

      {/* ìŒì„± ìë™ ì¬ìƒ */}
      {audioSrc && (
        <audio 
          ref={audioRef} 
          autoPlay 
          controls 
          className="mt-4"
          onEnded={() => setIsPlaying(false)} // ğŸ”¹ ìŒì„±ì´ ëë‚˜ë©´ ë‹¤ì‹œ ë…¹ìŒ ì‹œì‘ or ì¢…ë£Œ ì²´í¬
        >
          <source src={audioSrc} type="audio/mp3" />
          ë¸Œë¼ìš°ì €ê°€ ì˜¤ë””ì˜¤ íƒœê·¸ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        </audio>
      )}

      <Footer />
    </div>
  );
}
